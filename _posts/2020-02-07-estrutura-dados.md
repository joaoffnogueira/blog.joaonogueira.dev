---
title: AnotaÃ§Ãµes sobre Estruturas de Dados
author: JoÃ£o F. F. Nogueira
date: 2020-02-07 08:00:00 -0300
categories: [Estudos-faculdade]
tags: [dados]
toc: true
---

## 1 Estruturas de dados e anÃ¡lise de complexidade

### DEFINIÃ‡ÃƒO: ESTRUTURA DE DADOS

Todo o dado atÃ´mico Ã© aquele no qual o conjunto de dados manipulados Ã© indivisÃ­vel, ou seja, vocÃª trata-os como sendo um Ãºnico valor. Por sua vez, dados complexos sÃ£o aqueles cujos elementos do conjunto de valores podem ser decompostos em partes mais simples. Se um dado pode ser dividido, isso significa que ele apresenta algum tipo de organizaÃ§Ã£o estruturada e, portanto, Ã© chamado de dado estruturado, o qual faz parte de uma estrutura de dados.

Estruturas de dados homogÃªneas sÃ£o aquelas que manipulam um sÃ³ tipo de dado. VocÃª jÃ¡ deve ter tido contato com esse tipo de dado ao longo de seus estudos anteriores em programaÃ§Ã£o. Vetores sÃ£o estruturas homogÃªneas de dados. Um vetor serÃ¡ sempre unidimensional. Se desejarmos trabalhar com duas dimensÃµes, trabalhamos com matrizes e, mais do que duas dimensÃµes denominamos de tensores. Vetor Ã© um tipo de estrutura de dados linear que necessita de somente um Ã­ndice para indexaÃ§Ã£o dos endereÃ§os dos elementos. O vetor contÃ©m um nÃºmero fixo de cÃ©lulas. Cada cÃ©lula armazenarÃ¡ um Ãºnico valor, sendo todos estes valores do mesmo tipo de dados. Quando declaramos uma estrutura de vetor, na memÃ³ria do programa ele Ã© inicializado (alocado) a partir da primeira posiÃ§Ã£o (endereÃ§o da primeira cÃ©lula). Cada outra cÃ©lula, a partir da segunda, possui um endereÃ§o de referÃªncia relativoÃ  primeira cÃ©lula endereÃ§ada. Esse endereÃ§o Ã© calculado considerando a posiÃ§Ã£o da primeira cÃ©lula, acrescido do tamanho em bytes de cada cÃ©lula, tamanho que depende do tipo de dado armazenado no vetor. 

Chamamos isto de alocaÃ§Ã£o sequencial.

   ![alocaÃ§Ã£o sequencial](/posts/2021-01-08-1.png){: width="100" height="100" }

Uma matriz Ã© uma estrutura de dados homogÃªnea, linear, com alocaÃ§Ã£o sequencial e bidimensional. Para cada uma das dimensÃµes da matriz, Ã© necessÃ¡rio utilizar um Ã­ndice diferente. TambÃ©m podemos afirmar que cada dimensÃ£o de uma matriz Ã© na verdade um vetor. Em outras palavras, uma matriz Ã© um vetor de vetor. Considerando nosso exemplo bidimensional, nossa matriz Ã© composta, portanto, por dois vetores. Podemos generalizar a forma de cÃ¡lculo de cada posiÃ§Ã£o na memÃ³ria de uma matriz pela EquaÃ§Ã£o 2:ğ¸ğ‘›ğ‘‘ğ‘’ğ‘Ÿğ‘’Ã§ğ‘œğ‘–,ğ‘— = ğ¸ğ‘›ğ‘‘ğ‘’ğ‘Ÿğ‘’Ã§ğ‘œ0,0 + (Ãğ‘›ğ‘‘ğ‘–ğ‘ğ‘’ğ‘™ğ‘–ğ‘›â„ğ‘ âˆ— ğ¶ âˆ— ğ‘‡ğ‘ğ‘šğ‘ğ‘›â„ğ‘œğµğ‘¦ğ‘¡ğ‘’ğ‘ )+ (Ã­ğ‘›ğ‘‘ğ‘–ğ‘ğ‘’ğ‘ğ‘œğ‘™ğ‘¢ğ‘›ğ‘ âˆ— ğ‘‡ğ‘ğ‘šğ‘ğ‘›â„ğ‘œğµğ‘¦ğ‘¡ğ‘’ğ‘ ).

Estruturas de dados heterogÃªneas, tambÃ©m conhecidas como registros (ou structs na linguagem de programaÃ§Ã£o C).

### ANÃLISE DE COMPLEXIDADE DE ALGORITMOS

Ao analisarmos o desempenho de um algoritmo, existem dois parÃ¢metros que precisam ser observados:

- Tempo de execuÃ§Ã£o â€“ quando tempo um cÃ³digo levou para ser executado;
- Uso de memÃ³ria volÃ¡til â€“ a quantidade de espaÃ§o ocupado na memÃ³ria principal do computador; Acerca do tempo de execuÃ§Ã£o, um fator bastante relevante nesse parÃ¢metro Ã© o tamanho do conjunto de dados de entrada.

O custo em tempo de execuÃ§Ã£o de um algoritmo Ã© o tempo que ele demora para encerrar a sua execuÃ§Ã£o. Podemos medir de forma empÃ­rica esse tempo de execuÃ§Ã£o. As linguagens de programaÃ§Ã£o, e atÃ© o prÃ³prio compilador, fornecem recursos e ferramentas capazes de mensurar esses tempos.

Como forma de abstrair nossa anÃ¡lise do hardware e de softwares que sÃ£o alheios ao nosso desenvolvimento, podemos encontrar matematicamente o custo de um algoritmo, encontrando uma equaÃ§Ã£o que descreve o seu comportamento em relaÃ§Ã£o ao desempenho do algoritmo. Encontrar esse custo Ã© prever os recursos que o algoritmo utilizarÃ¡. A funÃ§Ã£o custo T(n) de um algoritmo qualquer pode ser dada como: ğ‘‡(ğ‘›) = ğ‘‡ğ‘¡ğ‘’ğ‘šğ‘ğ‘œ + ğ‘‡ğ‘’ğ‘ ğ‘ğ‘Ã§ğ‘œ.

Para encontrarmos esse custo em tempo de execuÃ§Ã£o, consideramos as seguintes restriÃ§Ãµes em nossas anÃ¡lises:

- Nossos cÃ³digos rodarÃ£o em um, e somente um, microprocessador por vez;Â· NÃ£o existirÃ£o operaÃ§Ãµes concorrentes, somente sequenciais;
- Consideraremos que todas as instruÃ§Ãµes do programa contÃªm um custo unitÃ¡rio, fixo e constante.

Uma instruÃ§Ã£o serÃ¡ uma operaÃ§Ã£o ou manipulaÃ§Ã£o simples realizada pelo programa, como: atribuiÃ§Ã£o de valores, acesso a valores de variÃ¡veis, comparaÃ§Ã£o de valores e operaÃ§Ãµes aritmÃ©ticas bÃ¡sicas.

Perceba que o pior caso e o melhor caso resultam em duas funÃ§Ãµes de custo diferentes.

### ANÃLISE ASSINTÃ“TICA DE ALGORITMOS

Nesse tipo de anÃ¡lise, encontraremos uma curva de tendÃªncia aproximada do desempenho de um algoritmo. A anÃ¡lise baseia-se na extrapolaÃ§Ã£o do conjunto de dados de entrada, fazendo-os tenderem ao infinito e permitindo que negligenciemos alguns termos de nossas equaÃ§Ãµes. Em outras palavras, descartamos de nossas equaÃ§Ãµes os termos que crescem lentamente Ã  medida que nosso conjunto de dados de entrada tende ao infinito.

Para obtermos o comportamento assintÃ³tico de qualquer funÃ§Ã£o, mantemos somente o termo de maior grau (maior crescimento) da equaÃ§Ã£o, negligenciando todos os outros, inclusive o coeficiente multiplicador do termo de maior grau.

a. GRANDE-O (BIG-O):

- Define o comportamento assintÃ³tico superior;
- Ã‰ o pior caso de um algoritmo;
- Mais instruÃ§Ãµes sendo executadas.

b. GRANDE-Ã”MEGA:

- Define o comportamento assintÃ³tico inferior;
- Ã‰ o melhor caso do algoritmo (caso Ã³timo);
- Menos instruÃ§Ãµes sendo executadas.

c. GRANDE-TETA:

- Define o comportamento assintÃ³tico firme;
- Caso mÃ©dio de um algoritmo. 
- Ã‰ o comportamento considerando a grande maioria dos casos.

Vamos trabalhar com o a notaÃ§Ã£o Big-O, que Ã© a notaÃ§Ã£o mais empregada em anÃ¡lises de algoritmos e nos diz que um cÃ³digo nunca serÃ¡ pior do que a situaÃ§Ã£o mostrada nesta notaÃ§Ã£o, podendo, no entanto, ser melhor, dependendo do conjunto de dados de entrada.

### RECURSIVIDADE

A recursÃ£o Ã© o processo de definiÃ§Ã£o de algo em termos de si mesmo. Um algoritmo recursivo Ã© aquele que utiliza a si prÃ³prio para atingir algum objetivo, ou obter algum resultado. Em programaÃ§Ã£o, a recursividade estÃ¡ presente quando uma funÃ§Ã£o realiza chamadas a si mesma.

Percebemos o interessante desempenho da funÃ§Ã£o recursiva, porÃ©m, como o algoritmo recursivo estÃ¡ abrindo muitas instÃ¢ncias de uma mesma funÃ§Ã£o, e para cada nova instÃ¢ncia temos suas variÃ¡veis locais sendo alocadas novamente, isso significa um aumento do uso de memÃ³ria desse programa. Portanto, deve-se tomar cuidado com a possibilidade de estouro da pilha de memÃ³ria em aplicaÃ§Ãµes recursivas.

## 2 Algoritmos de ordenaÃ§Ã£o e busca

### Algoritmos de ordenaÃ§Ã£o

Cada dado pertencente a uma coleÃ§Ã£o de dados deve conter um nÃºmero de registro (chave). Esta chave serve para identificar de forma Ãºnica um dado dentro de toda a coleÃ§Ã£o. Todos os dados que estÃ£o vinculados a uma chave sÃ£o chamados de dado satÃ©lite.

Uma maneira de otimizarmos um algoritmo Ã©, em vez de permutarmos toda a coleÃ§Ã£o de dados satÃ©lite de cada entrada de dados, vincular uma variÃ¡vel do tipo ponteiro a cada registro. Assim, permutamos e organizamos somente estes ponteiros, nÃ£o precisando realocar todo o conjunto de dados satÃ©lite em memÃ³ria, reduzindo o consumo de recursos, aumentando a eficiÃªncia o desempenho do processo.

Um algoritmo de ordenaÃ§Ã£o Ã© um mÃ©todo que descreve como Ã© possÃ­vel colocar, em uma ordem especÃ­fica, um conjunto de dados qualquer.

### Algoritmo de ordenaÃ§Ã£o por troca (bubble sort)

Apesar de ser o algoritmo de ordenaÃ§Ã£o mais simples, e frequentemente o mais utilizado para o entendimento do processo de ordenaÃ§Ã£o, este Ã© um algoritmo computacionalmente muito caro e muito ineficiente. Notadamente porque emprega dois laÃ§os de repetiÃ§Ã£o aninhados.

Dentro do laÃ§o interno, existe um teste condicional que compara o valor de uma posiÃ§Ã£o do vetor com o prÃ³ximo valor, efetuando uma troca entre eles, caso necessÃ¡rio, utilizando uma variÃ¡vel auxiliar.

Conforme vimos, o algoritmo proposto continua testando se os valores estÃ£o posicionados corretamente, mesmo quando o vetor jÃ¡ estÃ¡ ordenado. O que constitui desperdÃ­cio de recursos computacionais.

Podemos solucionar este problema e otimizar o desempenho de nosso cÃ³digo, bem como trocar nosso laÃ§o externo do tipo para por um laÃ§o enquanto(ou mesmo um repita). Neste laÃ§o de enquanto, continuaremos fazendo nossa contagem que vai atÃ© o tamanho do vetor, exatamente como antes, mas tambÃ©m acrescentamos outra condiÃ§Ã£o, uma variÃ¡vel do tipo lÃ³gico com dois estados, inicializada com nÃ­vel lÃ³gico baixo e que se mantÃ©m neste valor ao menos que exista uma troca. Portanto, enquanto houver trocas, seu valor serÃ¡ de nÃ­vel alto. Quando o nÃ­vel lÃ³gico volta a ser baixo, o laÃ§o encerrarÃ¡ precocemente, economizando nas iteraÃ§Ãµes desnecessÃ¡rias. 

A complexidade assintÃ³tica para o pior caso do mÃ©todo de ordenaÃ§Ã£o por troca, tanto para a versÃ£o original quanto para a versÃ£o aprimorada serÃ¡ igual. 

Lembrando que um laÃ§o de repetiÃ§Ã£o sÃ³ tem impacto no desempenho assintÃ³tico do algoritmo caso estejam aninhados, ou seja, um inserido no outro. Percebemos a existÃªncia de dois laÃ§os de repetiÃ§Ã£o aninhados. Portanto, temos para Big-O: 0ğµğ‘¢ğ‘ğ‘ğ‘™ğ‘’ğ‘†ğ‘œğ‘Ÿğ‘¡(ğ‘›Â²).

Analogamente, a versÃ£o aprimorada tambÃ©m tem dois laÃ§os aninhados, resultando na mesma complexidade para o pior caso. Se a complexidade Ã© a mesma, por que entÃ£o utilizamos a versÃ£o aprimorada? Porque para as situaÃ§Ãµes em que o pior caso nÃ£o ocorrerÃ¡, a nova versÃ£o se sairÃ¡ melhor.

### Algoritmo de OrdenaÃ§Ã£o por intercalaÃ§Ã£o (merge sort)

Este algoritmo de ordenaÃ§Ã£o trabalha com a divisÃ£o da estrutura de dados em partes menores, empregando uma tÃ©cnica chamada de dividir para conquistar. Para tal, empregam-se funÃ§Ãµes recursivas para a realizaÃ§Ã£o desta tarefa. 

O processo do merge sort consiste em dividir uma estrutura de dados de tamanho n (um vetor por exemplo) em n partes de tamanho unitÃ¡rio. Ou seja, o conjunto de dados inicial vai sendo dividido ao meio atÃ© que restem somente partes indivisÃ­veis. Quando duas partes subsequentes atingirem tamanho um, elas realizam o processo chamado de intercalaÃ§Ã£o. De forma simples, podemos entender a intercalaÃ§Ã£o como a ordenaÃ§Ã£o (crescente ou decrescente) seguida da agregaÃ§Ã£o das partes para formarem um vetor maior. 

   ![merge sort](/posts/2021-01-08-2.png){: width="100" height="100" }

Para encontrarmos a complexidade assintÃ³tica para o pior caso do merge sort, precisamos, primeiro, analisar a complexidade individual de ambas funÃ§Ãµes propostas. Temos a funÃ§Ã£o merge sendo chamada recursivamente. A complexidade assintÃ³tica para o pior caso de uma funÃ§Ã£o recursiva serÃ¡ ğ‘‚(ğ‘™ğ‘œğ‘”(ğ‘›)). 

A funÃ§Ã£o merge tambÃ©m faz a chamada de outra funÃ§Ã£o, a intercala. Esta funÃ§Ã£o opera de forma iterativa. NÃ£o temos laÃ§os encadeados, portanto a complexidade para um Ãºnico laÃ§o serÃ¡ ğ‘‚(ğ‘›).

Como a funÃ§Ã£o intercala estÃ¡ inserida na funÃ§Ã£o merge, para encontrar a complexidade assintÃ³tica Big-Oh resultante, multiplicamos a complexidade de ambas funÃ§Ãµes. A complexidade para o pior do merge sort Ã© superior em tempo de execuÃ§Ã£o se comparado com o bubble sort. 0ğ‘€ğ‘’ğ‘Ÿğ‘”ğ‘’ğ‘†ğ‘œğ‘Ÿğ‘¡(ğ‘›. log(ğ‘›))

### Algoritmo de ordenaÃ§Ã£o rÃ¡pida (quick sort)

O quick sort Ã© bastante empregado em virtude de sua eficiÃªncia e facilidade de implementaÃ§Ã£o. A ordenaÃ§Ã£o rÃ¡pida trabalha com o conceito de pivÃ´, em que um elemento do conjunto de dados Ã© selecionado para servir como referÃªncia de comparaÃ§Ã£o para os outros valores. 

A ordenaÃ§Ã£o ocorre quando o mÃ©todo divide a estrutura de dados em duas partes, semelhante ao merge sort, porÃ©m esta divisÃ£o nÃ£o necessariamente ocorre no ponto central do vetor. 

Diferentemente do merge sort, o objetivo deste algoritmo nÃ£o Ã© quebrar o vetor no menor tamanho possÃ­vel, mas sim dividi-lo para encontrar o elemento pivÃ´. Para uma ordenaÃ§Ã£o crescente, os elementos Ã  esquerda do pivÃ´ devem sempre ser menores do que ele, e os Ã  direita, maiores que o pivÃ´. O algoritmo Ã© aplicado de forma recursiva nas partes divididas atÃ© que a estrutura esteja ordenada.

A complexidade final para o quick sort serÃ¡ ğ‘‚ğ‘„ğ‘¢ğ‘–ğ‘ğ‘˜ğ‘†ğ‘œğ‘Ÿğ‘¡(ğ‘›2)

### Algoritmos de busca

Algoritmos de busca servem para localizar um valor especÃ­fico em um conjunto de dados. Assim como apresentado nos algoritmos de ordenaÃ§Ã£o, a quantidade de algoritmos de busca disponÃ­vel Ã© diversa, e cada um destes algoritmos apresentarÃ¡ vantagens e desvantagens, alÃ©m de desempenhos distintos e, consequentemente, aplicaÃ§Ãµes diferentes.

Busca sequencial

- A busca sequencial tem como fim introduzir o assunto de algoritmos de busca. A proposta do algoritmo de busca sequencial consiste em realizar uma busca em um conjunto de dados (ordenado ou nÃ£o), empregando ao menos um laÃ§o de repetiÃ§Ã£o que farÃ¡ a varredura do conjunto de dados (lÃ³gica iterativa). Para cada iteraÃ§Ã£o, temos uma comparaÃ§Ã£o simples entre o elemento a ser localizado e cada elemento deste conjunto de dados.
- A complexidade assintÃ³tica para o tempo de execuÃ§Ã£o da busca sequencial, com vetor ordenado ou nÃ£o, serÃ¡ sempre ğ‘‚(ğ‘›).

Busca binÃ¡ria

- A busca binÃ¡ria que trabalha com o conceito de dividir um conjunto de dados sempre ao meio e comparar o ponto central com o valor buscado Ã© o conhecido processo de dividir para conquistar. Se este ponto central for menor ou maior que o valor buscado, a regiÃ£o de busca do vetor Ã© limitada para o ramo esquerdo ou direto do conjunto de dados. Com esta proposta, a busca binÃ¡ria Ã© capaz de atingir seu objetivo mais rapidamente e, ainda, trabalhar com recursividade, tornando o mÃ©todo mais eficiente se comparado ao sequencial. 
- Uma caracterÃ­stica importante Ã© que a busca binÃ¡ria sÃ³ funciona com conjuntos de dados jÃ¡ ordenados, caso contrÃ¡rio, a verificaÃ§Ã£o feita com o ponto central nÃ£o seria possÃ­vel. Portanto, se o conjunto de dados nÃ£o estiver ordenado, ele primeiro precisa ser ordenado para depois ser buscado.
- A busca binÃ¡ria apresenta como complexidade assintÃ³tica ğ‘‚(ğ‘™ğ‘œğ‘”ğ‘›).

## 3 Listas, pilhas e filas

### Conceito de listas encadeadas

Nem todas as estruturas de dados sÃ£o sequenciais. Existem estruturas de dados com alocaÃ§Ã£o nÃ£o sequencial. Em estruturas de dados com alocaÃ§Ã£o nÃ£o sequencial, cada dado (ou conjunto de dados) pode estar posicionado em qualquer parte da memÃ³ria destinada a um programa em execuÃ§Ã£o.

AlÃ©m dos dados Ãºteis, cada elemento da lista ainda precisa manter pelo menos um endereÃ§o armazenado. Esse endereÃ§o corresponderÃ¡ ao endereÃ§o do prÃ³ximo elemento da lista. Dessa forma, cada elemento da lista sabe onde o prÃ³ximo estÃ¡ e todos estÃ£o conectados (virtualmente) por meio desses endereÃ§os, ou ponteiros, armazenados.

Para uma lista, o conceito de Ã­ndice Ã© inexistente. Em uma lista, cada elemento contÃ©m o endereÃ§o do prÃ³ximo elemento. Portanto, somente o elemento atual conhece o subsequente. Assim, a Ãºnica forma de acessarmos, por exemplo, o terceiro elemento dessa lista seria iniciarmos no primeiro elemento e, por meio do acesso aos endereÃ§os para os prÃ³ximos elementos, passarmos de um elemento para o seguinte atÃ© atingirmos o elemento desejado. Esse tipo de lista Ã© chamado de encadeado por esse motivo, jÃ¡ que os elementos estÃ£o encadeados por meio do endereÃ§o do elemento seguinte.

Uma das grandes vantagens do uso de listas encadeadas estÃ¡ na possibilidade de alocaÃ§Ã£o dinÃ¢mica de memÃ³ria e no dinamismo de manipulaÃ§Ã£o dos dados dessa lista, o que torna fÃ¡ceis a inserÃ§Ã£o e a remoÃ§Ã£o de novos elementos.

Dentre as desvantagens das listas estÃ¡ o desempenho para acesso aos dados. 

As listas podem ser homogÃªneas ou heterogÃªneas e armazenar qualquer tipo de dado.

### Lista simplesmente encadeada (linked list)

Cada elemento dela aponta e conhece somente o prÃ³ximo elemento da lista. Para tal, cada nÃ³ necessita ter um Ãºnico ponteiro, com o endereÃ§o do prÃ³ximo elemento. Em programaÃ§Ã£o, podemos representar cada elemento da lista encadeada como sendo um registro. Esse registro conterÃ¡ todos os dados que se deseja armazenar, sejam quais forem seus tipos, e tambÃ©m um ponteiro. Esse ponteiro conterÃ¡ o endereÃ§o para o prÃ³ximo elemento da lista. O tipo desse ponteiro deverÃ¡ ser igual ao do registro criado.

A lista encadeada simples pode ser classificada em dois tipos: as nÃ£o circulares e as circulares.

O primeiro elemento da lista Ã© chamado de inÃ­cio ou de head (cabeÃ§a) da lista. Esse primeiro elemento Ã© o Ãºnico que sempre serÃ¡ conhecido pelo programa que estÃ¡ manipulando uma determinada lista. Todos os outros dados da lista sÃ£o descobertos Ã  medida que os elementos da lista vÃ£o sendo acessados.

Em uma lista simples nÃ£o circular, o Ãºltimo elemento nÃ£o apontarÃ¡ para nada (ponteiro nulo). De uma forma diferente, a lista simples circular difere da nÃ£o circular somente pelo ponteiro do Ãºltimo nÃ³. Esse ponteiro, ao invÃ©s de apontar para o nulo, irÃ¡ apontar para o primeiro elemento da lista, fechando um cÃ­rculo. 

#### Inserindo um novo elemento no inÃ­cio da lista encadeada simples nÃ£o circular

Passo 1: alocar o novo elemento na memÃ³ria. Perceba que alocÃ¡-lo na memÃ³ria ainda nÃ£o significa inseri-lo na lista. Nesse momento, ele ainda estÃ¡ fora da lista.

Passo 2: fazer o ponteiro do novo elemento apontar para o head.

Passo 3: transformar o novo elemento no novo head da lista.

#### Inserindo um novo elemento no fim da lista encadeada simples nÃ£o circular

Passo 1: alocar o novo elemento na memÃ³ria. Perceba que alocÃ¡-lo na memÃ³ria ainda nÃ£o significa inseri-lo na lista. Nesse momento ele ainda estÃ¡ fora da lista.

Passo 2: realizar uma varredura, usando um laÃ§o de repetiÃ§Ã£o e comeÃ§ando no head, atÃ© localizar um elemento que aponte para o nulo. Esse elemento serÃ¡ o Ãºltimo e a inserÃ§Ã£o do novo elemento ocorrerÃ¡ apÃ³s ele.

Passo 3: fazer esse Ãºltimo elemento apontar para o nosso novo valor. O novo valor, como serÃ¡ entÃ£o o Ãºltimo, irÃ¡ apontar para o nulo.

#### Inserindo um novo elemento no meio da lista encadeada simples nÃ£o circular

Passo 1: alocar o novo elemento na memÃ³ria. Perceba que alocÃ¡-lo na memÃ³ria ainda nÃ£o significa inseri-lo na lista. Nesse momento, ele ainda estÃ¡ fora da lista.

Passo 2: realizar uma varredura, usando um laÃ§o de repetiÃ§Ã£o e comeÃ§ando no head atÃ© localizar a posiÃ§Ã£o desejada.

Passo 3: fazer o elemento da posiÃ§Ã£o anterior apontar para o novo elemento e fazer o novo elemento apontar o antigo da posiÃ§Ã£o desejada.

### Lista duplamente encadeada (doubly linked list)

Uma lista duplamente encadeada Ã© assim chamada pois cada elemento dela aponta e conhece o prÃ³ximo elemento da lista, bem como o elemento imediatamente anterior a ele na lista. Para tal, cada nÃ³ necessita ter dois ponteiros (anterior e prÃ³ximo).

Em programaÃ§Ã£o, podemos representar cada elemento da lista encadeada como sendo um registro. Esse registro conterÃ¡ todos os dados que se deseja armazenar, sejam quais forem seus tipos, e tambÃ©m os dois ponteiros. Um ponteiro conterÃ¡ o endereÃ§o para o prÃ³ximo elemento da lista e o outro, o endereÃ§o para retornar ao elemento anterior. O tipo desse ponteiro deverÃ¡ ser igual ao do registro criado.

A lista encadeada dupla pode ser classificada em dois tipos: as nÃ£o circulares e as circulares. Em uma lista dupla nÃ£o circular, o Ãºltimo elemento apontarÃ¡ para o nulo. De uma forma diferente, a lista dupla circular difere da nÃ£o circular somente pelo ponteiro prÃ³ximo do Ãºltimo nÃ³. Esse ponteiro, ao invÃ©s de apontar para o nulo, irÃ¡ apontar de volta para o primeiro elemento da lista, fechando um cÃ­rculo novamente.

#### Inserindo um novo elemento no inÃ­cio da lista encadeada dupla

Passo 1: alocar o novo elemento na memÃ³ria. Perceba que alocÃ¡-lo na memÃ³ria ainda nÃ£o significa inseri-lo na lista. Nesse momento, ele ainda estÃ¡ fora da lista.

Passo 2: fazer o ponteiro prÃ³ximo do novo elemento apontar para o head. Fazer o ponteiro anterior ao novo elemento apontar para o nulo. Fazer o ponteiro anterior ao head apontar para o novo elemento.

Passo 3: transformar o novo elemento no novo head da lista.

#### Inserindo um novo elemento no fim da lista encadeada dupla

Passo 1: alocar o novo elemento na memÃ³ria. Perceba que alocÃ¡-lo na memÃ³ria ainda nÃ£o significa inseri-lo na lista. Nesse momento, ele ainda estÃ¡ fora da lista.

Passo 2: realizar uma varredura na lista existente, iniciando no head, atÃ© localizar o elemento com ponteiro prÃ³ximo nulo (Ãºltimo elemento).

Passo 3: fazer o elemento encontrado, com ponteiro prÃ³ximo nulo, apontar para o novo elemento. Fazer o ponteiro anterior ao novo elemento apontar para o Ãºltimo elemento. Fazer o ponteiro prÃ³ximo do novo elemento apontar para o nulo.

#### Inserindo um novo elemento no meio da lista encadeada dupla

Passo 1: alocar o novo elemento na memÃ³ria. Perceba que alocÃ¡-lo na memÃ³ria ainda nÃ£o significa inseri-lo na lista. Nesse momento, ele ainda estÃ¡ fora da lista.

Passo 2: executar uma varredura na lista existente, iniciando no head, atÃ© localizar a posiÃ§Ã£o desejada (posiÃ§Ã£o 2).

Passo 3: utilizando uma variÃ¡vel de lista auxiliar, fazer a inserÃ§Ã£o do elemento no meio. O elemento da posiÃ§Ã£o 1 irÃ¡ apontar para o novo elemento, com seu ponteiro prÃ³ximo. O antigo elemento da posiÃ§Ã£o 2 apontarÃ¡, com seu anterior, tambÃ©m para o novo elemento. O novo elemento irÃ¡ apontar, com seu ponteiro anterior, para o 9 e, com seu ponteiro prÃ³ximo, para o 5.

### Pilha (stack)

Uma pilha se comporta seguindo a regra chamada: o primeiro que entra Ã© o Ãºltimo que sai. Em inglÃªs, essa regra Ã© chamada de first in last out (Filo).

Em programaÃ§Ã£o, podemos criar uma estrutura de dados que tambÃ©m funciona com esse princÃ­pio que acaba de ser explicado. Essa estrutura pode ser construÃ­da tanto com vetores quanto com listas encadeadas. Ambas funcionarÃ£o da mesma maneira detalhada anteriormente. As diferenÃ§as estarÃ£o nas caracterÃ­sticas da estrutura de dados, caracterÃ­sticas essas intrÃ­nsecas a elas. Vetores funcionarÃ£o com alocaÃ§Ã£o sequencial da memÃ³ria e tempo de acesso aos dados constante. Listas funcionarÃ£o com alocaÃ§Ã£o dinÃ¢mica e tempo de acesso Ã s informaÃ§Ãµes ğ‘‚(ğ‘›).

Dentre algumas aplicaÃ§Ãµes comuns de pilhas estÃ¡ a prÃ³pria tÃ©cnica de programaÃ§Ã£o chamada recursividade, jÃ¡ bastante desenvolvida nas aulas anteriores. Cada instÃ¢ncia de uma funÃ§Ã£o recursiva aberta Ã© tratada como um novo elemento inserido na pilha. Esse novo elemento precisa ser resolvido para entÃ£o desempilharmos os demais elementos e assim termos acesso ao elemento (outra funÃ§Ã£o) que estÃ¡ abaixo, na pilha.

Top, Ãºnico elemento sempre conhecido globalmente pelo programa. 

#### Inserindo um novo elemento na pilha (empilhando/push)

Passo 1: alocar o novo elemento na memÃ³ria. Perceba que alocÃ¡-lo na memÃ³ria ainda nÃ£o significa inseri-lo na pilha. Nesse momento, ele ainda estÃ¡ fora da pilha.

Passo 2: fazer o ponteiro do novo elemento apontar para o top.

Passo 3: transformar o novo elemento no novo top da lista.

#### Removendo um elemento da pilha (desempilhando/pop)

Passo 1: localizar o topo da pilha.

Passo 2: transformar o elemento subsequente ao topo no novo topo.

Passo 3: liberar da memÃ³ria o topo antigo, para que ele nÃ£o ocupe espaÃ§o desnecessÃ¡rio na memÃ³ria do programa.

### Fila (Queue)

Uma fila se comporta seguindo a regra chamada: o primeiro que entra Ã© o primeiro que sai. Em inglÃªs, essa regra Ã© chamada de first in first out (Fifo).

Em programaÃ§Ã£o, podemos criar uma estrutura de dados que tambÃ©m funciona com esse princÃ­pio que acaba de ser explicado. Essa estrutura pode ser construÃ­da tanto com vetores quanto com listas encadeadas. 

Dentre algumas aplicaÃ§Ãµes comuns de filas na Ã¡rea de tecnologia, podemos citar o processo de fila de impressÃ£o, em uma rede. Cada arquivo que Ã© colocado para imprimir, em uma mesma impressora, Ã© inserido no final da fila. E o que estÃ¡ na frente da fila Ã© removido (impresso) primeiro.

#### Inserindo um elemento na fila (queuing)

Passo 1: alocar o novo elemento na memÃ³ria. Perceba que alocÃ¡-lo na memÃ³ria ainda nÃ£o significa inseri-lo na pilha. Nesse momento, ele ainda estÃ¡ fora da fila.

Passo 2: varrer a fila atÃ© encontrar o ponteiro nulo (Ãºltimo elemento).

Passo 3: fazer o ponteiro nulo do Ãºltimo elemento apontar para o novo elemento.

#### Removendo da fila (dequeuing)

Passo 1: localizar o head da fila.

Passo 2: transformar o elemento subsequente ao head no novo head.

Passo 3: liberar da memÃ³ria o head antigo, para que ele nÃ£o ocupe espaÃ§o desnecessÃ¡rio na memÃ³ria do programa

## 4 Ãrvores

### Ãrvore binÃ¡ria

A Ã¡rvore binÃ¡ria Ã© uma estrutura de dados nÃ£o linear organizada com elementos que nÃ£o estÃ£o, necessariamente, encadeados, formando ramificaÃ§Ãµes e subdivisÃµes na organizaÃ§Ã£o da estrutura de dados. A Ã¡rvore binÃ¡ria apresenta algumas caracterÃ­sticas distintas, mesmo se comparada a outros tipos de Ã¡rvores. Analisaremos algumas dessas caracterÃ­sticas e conceituaremos alguns termos prÃ³prios referentes a Ã¡rvores:

Â· NÃ³ raiz (root):1 nÃ³ original da Ã¡rvore. Todos derivam dele;

Â· NÃ³ pai: nÃ³ que dÃ¡ origem (estÃ¡ acima) a pelo menos um outro nÃ³;

Â· NÃ³ filho: nÃ³ que deriva de um nÃ³ pai;

Â· NÃ³ folha/terminal: nÃ³ que nÃ£o contÃ©m filhos.

O que caracteriza uma Ã¡rvore como binÃ¡ria Ã© o nÃºmero de ramificaÃ§Ãµes de cada nÃ³. Na Ã¡rvore binÃ¡ria, cada nÃ³ apresenta nenhum, um ou no mÃ¡ximo dois nÃ³s chamados de nÃ³s filhos.

Uma Ã¡rvore binÃ¡ria apresenta como caracterÃ­stica a inserÃ§Ã£o de valores de forma organizada. Um modo de inserÃ§Ã£o de valores Ã© posicionar Ã  esquerda de um nÃ³ pai, na Ã¡rvore, somente valores menores do que ele. E os valores Ã  direita devem ser maiores que o nÃ³ pai. Desse modo, valores menores sÃ£osempre posicionados mais Ã  esquerda da Ã¡rvore e os maiores mais Ã  direita. Esse tipo de inserÃ§Ã£o Ã© tambÃ©m conhecido como Binary Search Tree (BST, Ã¡rvore de busca binÃ¡ria).

O objetivo de inserÃ§Ã£o na Ã¡rvore Ã© justamente facilitar a busca de dados posteriormente. Como os dados estarÃ£o colocados na Ã¡rvore de uma forma organizada, saberemos que, ao percorrer as ramificaÃ§Ãµes de uma Ã¡rvore binÃ¡ria, localizaremos o valor desejado mais rapidamente pelas subdivisÃµes.

O grau de um nÃ³ na estrutura de dados em Ã¡rvore corresponde ao nÃºmero de subÃ¡rvores que aquele nÃ³ terÃ¡. Em uma Ã¡rvore binÃ¡ria, o grau mÃ¡ximo de cada nÃ³ serÃ¡ dois.

Em uma Ã¡rvore, conceituamos o nÃ³ raiz como sendo o nÃ­vel zero da Ã¡rvore. Todo novo conjunto de ramificaÃ§Ãµes da Ã¡rvore caracteriza mais um nÃ­vel nessa Ã¡rvore. Conhecendo os nÃ­veis, a altura de uma Ã¡rvore serÃ¡ calculada ao tomarmos o maior nÃ­vel dela e subtrairmos do primeiro nÃ­vel (nÃ­vel 0). Ã‰ tambÃ©m possÃ­vel encontrarmos a altura relativa entre dois nÃ­veis da Ã¡rvore. Para isso, basta subtrairmos os valores desses nÃ­veis.

Em programaÃ§Ã£o, representamos cada elemento da Ã¡rvore como sendo um registro que contÃ©m todos os dados que desejamos armazenar, alÃ©m de dois ponteiros. Esses ponteiros conterÃ£o os endereÃ§os para os prÃ³ximos elementos da Ã¡rvore, ou seja, para os nÃ³s filhos daquele elemento.

Sempre que um nÃ³ for folha, significa que ele estÃ¡ no nÃ­vel mais alto da Ã¡rvore e que, portanto, nÃ£o terÃ¡ filhos. Sendo assim, ambos os ponteiros serÃ£o nulos. Caso o nÃ³ nÃ£o seja folha, ele sempre terÃ¡ ao menos um ponteiro de endereÃ§o nÃ£o nulo.

Raiz (root), Ãºnico elemento sempre conhecido globalmente pelo programa.

#### InserÃ§Ã£o de dados

Em uma Ã¡rvore binÃ¡ria montada para funcionar como uma Binary Seach Tree (BST) nÃ£o existem inserÃ§Ãµes no inÃ­cio, no meio nem no final da Ã¡rvore como ocorre nas listas encadeadas. A inserÃ§Ã£o sempre Ã© feita apÃ³s um dos nÃ³s folha da Ã¡rvore, seguindo a regra anteriormente explanada:

â€¢ Â· Dados de valores menores cujos antecessores sÃ£o inseridos no ramo esquerdo da Ã¡rvore;

â€¢ Â· Dados de valores maiores cujos antecessores sÃ£o inseridos no ramo direito da Ã¡rvore.

Todo novo nÃ³ inserido vira um nÃ³ folha, porque ele Ã© sempre inserido nos nÃ­veis mais altos da Ã¡rvore. Todos os nÃ³s folha podem ser facilmente identificados em uma Ã¡rvore como aqueles nÃ³s cujos ponteiros (esquerdo e direito) sÃ£o nulos.

Passo 1: Alocar o elemento na memÃ³ria (fora da Ã¡rvore);

Passo 2: Encontrar a posiÃ§Ã£o deste elemento na Ã¡rvore;

Passo 3: Fazer o ponteiro do nÃ³-pai apontar para o novo elemento.

#### Busca de dados

Passo 1: iniciando na raiz, testamos se ela Ã© igual, maior ou menor que o valor 2. Caso fosse igual, nossa busca jÃ¡ poderia ser encerrada. PorÃ©m, o valor 8 Ã© maior que 2. Isso significa que, caso o 2 exista nessa Ã¡rvore, ele estarÃ¡ Ã  esquerda do 8, e, portanto, devemos seguir pelo ramo esquerdo (ponteiro esquerdo);

Passo 2: estamos no nÃ­vel 1 da Ã¡rvore e comparando o valor 2 com o valor 6. Novamente, verificamos se esse valor Ã© maior, menor ou igual 2. O valor Ã© maior do que 2. Portanto, novamente, caso o 2 exista nessa Ã¡rvore, ele estarÃ¡ Ã  esquerda de 6, e devemos seguir para a esquerda no prÃ³ximo nÃ­vel;

Passo 3: estamos no nÃ­vel 2 da Ã¡rvore e comparamos o valor com o 2. Nesse caso, o valor Ã© exatamente 2, e, portanto, podemos encerrar nossa busca na Ã¡rvore binÃ¡ria.

A busca binÃ¡ria delimita a regiÃ£o de busca sempre pela metade a cada nova tentativa, tornando possÃ­vel localizar, para o pior caso assintÃ³tico, o dado em um tempo de execuÃ§Ã£o O(logn).

Uma Ã¡rvore binÃ¡ria tambÃ©m apresenta para BigO a mesma complexidade O(logn), tambÃ©m delimitando a regiÃ£o de busca sempre pela metade a cada novo nÃ­vel da Ã¡rvore. Sendo assim, a Ã¡rvore binÃ¡ria faz para as buscas em estruturas de dados dinÃ¢micas o equivalente ao que a busca binÃ¡ria faz para conjuntos de dados sequenciais. 

#### VisualizaÃ§Ã£o de dados

Uma Ã¡rvore binÃ¡ria, depois de construÃ­da, pode ser listada/consultada e apresentada em uma interface. PorÃ©m, como a Ã¡rvore nÃ£o apresenta sequÃªncia/ordem fixas, podemos listar seus dados de algumas formas distintas. As consultas podem ser feitas:

Em ordem: listamos os elementos iniciando pelos elementos da esquerda; depois, a raiz; e, por Ãºltimo, os elementos da direita. Dessa forma, os elementos listados sÃ£o apresentados ordenados e de forma crescente;

Em prÃ©-ordem: listamos os elementos iniciando pela raiz, depois listamos os elementos da esquerda, e, por fim, os elementos da direita;

Em pÃ³s-ordem: listamos os elementos iniciando pelos elementos da esquerda; depois, os da direita; e, por Ãºltimo, a raiz.

### Ãrvore de Adelson-Velsky e Landis (Ãrvore AVL)

Uma Ã¡rvore de Adelson-Velsky e Landis, tambÃ©m conhecida como Ã¡rvore AVL, Ã© uma Ã¡rvore binÃ¡ria balanceada. Em uma Ã¡rvore binÃ¡ria convencional, na medida em que temos muitas inserÃ§Ãµes de dados, podemos comeÃ§ar a ter algumas ramificaÃ§Ãµes que se estendem muito em altura, gerando piora no desempenho do algoritmo. 

RamificaÃ§Ãµes muito altas acabam dificultando o sistema de busca em uma Ã¡rvore, piorando o desempenho do algoritmo em termos de tempo de execuÃ§Ã£o. A Ã¡rvore AVL tem como objetivo melhorar esse desempenho balanceando uma Ã¡rvore binÃ¡ria, evitando ramos longos e gerando o maior nÃºmero de ramificaÃ§Ãµes binÃ¡rias possÃ­veis. 

Sendo assim, a Ã¡rvore AVL contÃ©m todas as caracterÃ­sticas jÃ¡ apresentadas de uma Ã¡rvore binÃ¡ria. A Ãºnica caracterÃ­stica adicional Ã© que a diferenÃ§a de altura entre uma subÃ¡rvore direita e uma subÃ¡rvore esquerda sempre deverÃ¡ ser 1, 0 ou â€“1. Caso essa diferenÃ§a resulte em outro valor, como 2 ou â€“2, a Ã¡rvore deverÃ¡ ser imediatamente balanceada (seus elementos deverÃ£o ser rearranjados) por meio de um algoritmo de balanceamento. 

Â· Passo 1: calculamos a altura relativa daquele elemento para o lado direito da Ã¡rvore. Nesse caso, pegamos o nÃ­vel mais alto do lado direito daquele elemento e subtraÃ­mos do nÃ­vel do elemento desejado;

Â· Passo 2: calculamos a altura relativa daquele elemento para o lado esquerdo da Ã¡rvore. Nesse caso, pegamos o nÃ­vel mais alto do lado esquerdo daquele elemento e subtraÃ­mos do nÃ­vel do elemento desejado;

Â· Passo 3: tendo as alturas direita e esquerda calculadas, fazemos a diferenÃ§a entre elas (direta menos esquerda, sempre). Se o cÃ¡lculo resultar em 2 ou â€“2, existe um desbalanceamento e uma rotaÃ§Ã£o serÃ¡ necessÃ¡ria. 

### Rotacionando a Ã¡rvore binÃ¡ria

| DiferenÃ§a de altura de um nÃ³ | DiferenÃ§a de altura entre o nÃ³ filho e o nÃ³ desbalanceado |                   Tipo de rotaÃ§Ã£o                    |
| :--------------------------: | :-------------------------------------------------------: | :--------------------------------------------------: |
|              2               |                             1                             |                  Simples Ã  esquerda                  |
|              2               |                             0                             |                  Simples Ã  esquerda                  |
|              2               |                            -1                             | Dupla com filho para a direita e pai para a esquerda |
|              -2              |                             1                             | Dupla com filho para a esquerda e pai para a direita |
|              -2              |                             0                             |                  Simples Ã  direita                   |
|              -2              |                            -1                             |                  Simples Ã  direita                   |

## 5 Grafos

Estrutura de dados que tem a sua construÃ§Ã£o sem um padrÃ£o definido e totalmente aleatÃ³ria.

Um grafo G Ã© um conjunto de vÃ©rtices conectados por meio de arestas sem uma distribuiÃ§Ã£o fixa ou padronizada. 

Os vÃ©rtices V de um grafo sÃ£o seus pontos. Cada ponto pode ser um ponto de encontro entre caminhos (rotas) de um grafo, ou, entÃ£o, o vÃ©rtice pode conter informaÃ§Ãµes relevantes para o grafo, como dados de informaÃ§Ãµes de cadastros. Tudo depende da aplicaÃ§Ã£o.

As arestas E sÃ£o as linhas de conexÃ£o entre os vÃ©rtices. Cada aresta conecta dois vÃ©rtices. Nem todo vÃ©rtice precisa ter uma aresta conectada; ele pode permanecer isolado, caso o grafo assim seja construÃ­do.

Chamamos de grafo completo quando existe uma, e somente uma aresta para cada par distinto de vÃ©rtices; chamamos de grafo trivial aquele que apresenta um Ãºnico vÃ©rtice.

Assim como tÃ­nhamos o grau de cada nÃ³ de uma Ã¡rvore, em grafos tambÃ©m podemos encontrar o grau de cada nÃ³ de um vÃ©rtice. O grau de um vÃ©rtice nada mais Ã© do que a soma de todas as arestas que incidem sobre ele. 

Dentre as particularidades da construÃ§Ã£o de grafos, podemos citar as arestas mÃºltiplas. Arestas mÃºltiplas sÃ£o aquelas que estÃ£o conectadas aos mesmos vÃ©rtices. 

Um laÃ§o acontece quando uma aresta contÃ©m somente um vÃ©rtice ao qual se conectar, iniciando e terminando nele. 

Por fim, vemos um grafo desconexo. Nesse tipo de grafo, temos pelo menos um vÃ©rtice sem nenhuma aresta 

Para finalizar a abordagem da teoria, precisamos entender que podemos atribuir pesos a nossas arestas. O peso da aresta representa um custo atrelado Ã quele caminho. Quando nÃ£o indicamos nenhum peso nas arestas, assumimos que elas tÃªm todas o mesmo valor. Quando damos um nÃºmero para cada aresta, indicamos os valores no prÃ³prio desenho do grafo. Chamamos um grafo com pesos em arestas de grafo ponderado.

### RepresentaÃ§Ã£o de grafos

Podemos representar os grafos matematicamente ou graficamente. As representaÃ§Ãµes matemÃ¡ticas acabam por ser ideais para a implementaÃ§Ã£o em um algoritmo, por exemplo, jÃ¡ que podem ser manipuladas da forma que o desenvolvedor necessitar.

#### Matriz de incidÃªncias

A representaÃ§Ã£o de um grafo por uma matriz de incidÃªncias consiste em criar uma matriz de dimensÃ£o VxE, em que V Ã© o nÃºmero de vÃ©rtices do grafo e E, o nÃºmero de arestas. 

Ao analisar o grafo desenhado, devemos observar cada uma de suas arestas (colunas da matriz). Elas devem ser preenchidas segundo as possibilidades a seguir:

0, caso o vÃ©rtice (linha da matriz) nÃ£o faÃ§a parta da ligaÃ§Ã£o;

1, caso o vÃ©rtice (linha da matriz) faÃ§a parta da ligaÃ§Ã£o;

2, caso aquela aresta seja do tipo laÃ§o.

   ![Matriz de incidÃªncias](/posts/2021-01-08-3.png){: width="100" height="100" }

#### Matriz de adjacÃªncias

A representaÃ§Ã£o de um grafo por uma matriz de adjacÃªncias consiste em criar uma matriz quadrada de dimensÃ£o V, em que V Ã© o nÃºmero de vÃ©rtices do grafo.

Assim como na representaÃ§Ã£o anterior, povoamos nossa matriz com valores 0, 1 ou 2. A anÃ¡lise que fazemos para preenchimento da matriz Ã© efetuada de uma forma diferente agora. Observamos cada uma das linhas dos vÃ©rtices, e preenchemos na matriz:

0, caso o outro vÃ©rtice nÃ£o tenha conexÃ£o com o vÃ©rtice analisado;

1, caso o outro vÃ©rtice tenha conexÃ£o com o vÃ©rtice analisado;

2, caso o outro vÃ©rtice tenha conexÃ£o com o vÃ©rtice analisado e seja um laÃ§o.

   ![Matriz de adjacÃªncias](/posts/2021-01-08-4.png){: width="100" height="100" }

#### Lista de adjacÃªncias

A representaÃ§Ã£o de um grafo por uma lista de adjacÃªncias Ã© muito adotada na Ã¡rea de programaÃ§Ã£o, pois trabalha com listas encadeadas e manipulaÃ§Ã£o de ponteiros de dados.

A proposta dessa representaÃ§Ã£o Ã© criar um vetor (ou uma lista encadeada) do tamanho da quantidade de vÃ©rtices existentes no grafo. Em cada posiÃ§Ã£o desse vetor, teremos uma lista encadeada contendo os endereÃ§os dos vizinhos de cada vÃ©rtice. Conceitualmente, vizinhos de um vÃ©rtice sÃ£o todos os vÃ©rtices que se conectam diretamente a ele por meio de uma aresta.

Assim, teremos uma lista encadeada de vizinhos para cada posiÃ§Ã£o do vetor de vÃ©rtices criado. Na lista, cada vizinho apontarÃ¡ para outro vizinho daquele mesmo nÃ³.

   ![Lista de adjacÃªncias](/posts/2021-01-08-5.png){: width="100" height="100" }

Podemos criar essa estrutura de duas formas distintas. Na primeira, declaramos um vetor de dimensÃ£o igual ao nÃºmero de vÃ©rtices de nosso grafo. Esse vetor serÃ¡ do tipo ponteiros de registros. Assim, cada posiÃ§Ã£o do vetor poderÃ¡ conter uma estrutura do tipo lista encadeada, armazenando o primeiro elemento dessa lista (head).

De forma alternativa, tambÃ©m podemos substituir o vetor por uma estrutura do tipo lista. Assim, teremos duas listas encadeadas, uma chamada de vertical, contendo os vÃ©rtices e os endereÃ§os para os primeiros vizinhos, e uma lista horizontal, contendo as listas de vizinhos de cada vÃ©rtice.

### Algoritmo de busca em profundidade no grafo

O algoritmo de busca em profundidade, tambÃ©m conhecido como Depth-First Search (DFS), apresenta uma lÃ³gica intuitiva e funcional para resolver esse problema de descoberta do grafo.

A proposta desse algoritmo Ã© partir de um vÃ©rtice de origem e acessar a lista de adjacÃªncias desse vÃ©rtice, ou seja, seus vizinhos. O primeiro vizinho detectado (mais adiante na lista encadeada do vÃ©rtice de origem), serÃ¡ imediatamente acessado. 

Assim, cada novo elemento ainda nÃ£o descoberto Ã© selecionado a partir das listas encadeadas de cada vÃ©rtice, atÃ© que o Ãºltimo seja encontrado. Os elementos descobertos vÃ£o sendo empilhados e desempilhados segundo as regras de uma estrutura do tipo pilha. Ou seja, sÃ³ podemos voltar ao vizinho de um nÃ³ mais abaixo na pilha se resolvermos primeiro o elemento mais acima, no topo da pilha.

### Algoritmo de busca em largura no grafo

O algoritmo de busca em largura, tambÃ©m conhecido como Breadth-First Search (BFS), trabalha com a ideia de visitar primeiro todos os vizinhos prÃ³ximos do vÃ©rtice selecionado antes de pular para o prÃ³ximo vÃ©rtice. 

Uma diferenÃ§a interessante em relaÃ§Ã£o Ã  busca por profundidade Ã© que a BFS trabalha com uma estrutura do tipo fila para indicar qual Ã© o prÃ³ximo vÃ©rtice a ser acessado, enquanto na Depth-first Search (DFS) tÃ­nhamos uma estrutura de pilha. 

Perceba que temos tambÃ©m um vetor de distÃ¢ncias. Esse vetor manterÃ¡ armazenada a distÃ¢ncia de cada vÃ©rtice em relaÃ§Ã£o ao vÃ©rtice de origem, ajudando na decisÃ£o de qual serÃ¡ o prÃ³ximo vÃ©rtice a ser visitado.

### Algoritmo do caminho mÃ­nimo em grafo: Dijkstra

Esse algoritmo Ã© o mais tradicional para realizar a tarefa de encontrar um caminho. Para realizar tal procedimento, podemos utilizar um grafo ponderado, ou seja, aquele com pesos distintos nas arestas.

Todo esse algoritmo serÃ¡ apresentado utilizando uma mÃ©trica aditiva. Isso significa que essa mÃ©trica encontrarÃ¡ a menor rota considerando o menor peso somado entre os caminhos. 

Existem outros tipos de mÃ©tricas. Na multiplicativa, por exemplo, o melhor caminho Ã© encontrado calculando-se o produto dos pesos das arestas. O maior valor dentre os produtos Ã© a melhor rota. Um exemplo dessa mÃ©trica Ã© o limite de velocidade das estradas: quanto maior o limite, mais rÃ¡pido o veÃ­culo anda, e, portanto, melhor Ã© aquela rota/aresta.

Como trabalharemos com um grafo ponderado, precisamos adaptar nossa lista de adjacÃªncias para que o registro tambÃ©m armazene os pesos das arestas. 

O algoritmo do caminho mÃ­nimo precisa calcular as menores rotas de um vÃ©rtice para todos os outros. Portanto, um vetor com distÃ¢ncias fica armazenado. Nesse vetor, todas as rotas iniciam com um valor infinito, ou seja, como se o caminho de um vÃ©rtice atÃ© o outro nÃ£o fosse conhecido. Ã€ medida que os trajetos vÃ£o sendo calculados, os pesos das rotas sÃ£o alterados.

## 6 Hashs

O objetivo da hash Ã© construir uma estrutura de dados capaz de obter tempo de acesso constante Ã s informaÃ§Ãµes contidas nela, independentemente do tamanho do conjunto de dados.

O vetor contendo os valores-chave Ã© denominado de tabela hashing. Para cada palavra-chave, podemos ter a quantidade que necessitarmos de dados cadastrados referentes aquela chave, dados estes chamados de dados satÃ©lites.

Tabelas hashing armazenam palavras-chave que servem para acessar dados satÃ©lite. Essas palavras-chave sÃ£o armazenadas em posiÃ§Ãµes de um vetor calculadas com base em funÃ§Ãµes hashing.

### FunÃ§Ãµes Hash

Um exemplo de funÃ§Ã£o hash pode ser aquele que leva em consideraÃ§Ã£o o resto de uma divisÃ£o para definir a posiÃ§Ã£o na estrutura de dados. PorÃ©m uma funÃ§Ã£o hash nÃ£o apresenta uma fÃ³rmula definida, e deve ser projetada levando-se em consideraÃ§Ã£o o tamanho do conjunto de dados, seu comportamento e os tipos de dados-chave utilizados.

As funÃ§Ãµes hash sÃ£o o cerne na construÃ§Ã£o das tabelas hashing, e o desenvolvimento de uma boa funÃ§Ã£o de hash Ã© essencial para que o armazenamento dos dados, a busca e o tratamento de colisÃµes (assunto abordado no prÃ³ximo tema) ocorram de forma mais eficiente possÃ­vel. Uma boa funÃ§Ã£o hash, em suma, deve ser:

FÃ¡cil de ser calculada. De nada valeria termos uma funÃ§Ã£o com cÃ¡lculos tÃ£o complexos e lentos que todo o tempo que seria ganho no acesso a informaÃ§Ã£o com complexidade ğ‘‚(1), seria perdido calculando uma custosa funÃ§Ã£o de hash;

Capaz de distribuir palavras-chave o mais uniforme possÃ­vel;

Capaz de minimizar colisÃµes. Os dados devem ser inseridos de uma forma que as colisÃµes sejam as mÃ­nimas possÃ­veis, reduzindo o tempo gasto resolvendo colisÃµes e tambÃ©m reavendo os dados;

Capaz de resolver qualquer colisÃ£o que ocorrer;

#### O mÃ©todo da divisÃ£o

Um tipo de funÃ§Ã£o hash muito adotada Ã© o mÃ©todo da divisÃ£o, em que dividimos dois valores inteiros e usamos o resto dessa divisÃ£o como a posiÃ§Ã£o desejada.

Quando nossas palavras-chave sÃ£o valores inteiros, dividimos o nÃºmero pelo tamanho do vetor e usamos o resto dessa divisÃ£o como a posiÃ§Ã£o a ser manipulada na tabela hashing. Caso uma palavra-chave adotada seja um conjunto grande de valores inteiros (como um nÃºmero telefÃ´nico ou CPF por exemplo), poderÃ­amos somar esses valores agrupados (em pares ou trios) e tambÃ©m dividir pelo tamanho do vetor, obtendo o resto da divisÃ£o. 

De modo geral, quando precisamos mapear um nÃºmero de chaves em m espaÃ§os (como os de um vetor) pegando o resto da divisÃ£o entre ambos, chamamos isso de mÃ©todo da divisÃ£o. Esse mÃ©todo Ã© bastante rÃ¡pido, uma vez que requer unicamente uma divisÃ£o. â„(ğ‘˜) = ğ‘˜ ğ‘€ğ‘‚ğ· ğ‘š

Existem alguns valores de m que devem ser minuciosamente escolhidos para nÃ£o gerar povoamentos de tabelas hash ruins. Por exemplo, utilizar 2 ou mÃºltiplos de 2 para o valor de m tende a nÃ£o ser uma escolha. Isso porque o resto da divisÃ£o por dois, ou qualquer mÃºltiplo seu, sempre resultarÃ¡ em um dos bits menos significativos, gerando um nÃºmero bastante elevado de colisÃµes de chaves.

Em hash precisamos trabalhar com nÃºmeros naturais para definir as posiÃ§Ãµes na tabela, uma vez que linguagens de programaÃ§Ã£o indexam as estruturas de dados (como vetores e matrizes) usando esse tipo de dado numÃ©rico. Desse modo, precisamos que nossas chaves sejam tambÃ©m valores naturais. Caso nÃ£o sejam, precisamos encontrar uma forma de transformÃ¡-las para que sejam. 

Para chaves com caracteres alfanumÃ©ricos, podemos adotar a mesma EquaÃ§Ã£o, fazendo pequenas adaptaÃ§Ãµes. Convertemos os caracteres para nÃºmeros decimais seguindo uma codificaÃ§Ã£o (tabela ASCII, por exemplo), somamos os valores, dividimos pelo tamanho do vetor e obtemos o resto da divisÃ£o como posiÃ§Ã£o de inserÃ§Ã£o da palavra-chave na tabela hashing. 

Adotar nÃºmeros primos, especialmente aqueles nÃ£o muito prÃ³ximos aos valores de potÃªncia de 2, tende a ser uma boa escolha para o tamanho do vetor com palavras-chaves alfanumÃ©ricas.

Por fim, quando trabalhamos com valores-chave sendo conjuntos de caracteres, devemos tomar cuidado com palavras que contenham as mesmas letras, mas em ordens diferentes (anagrama). Por exemplo, uma palavra-chave com quatro caracteres chamada ROMA poderÃ¡ gerar o mesmo resultado que uma palavra-chave chamada AMOR, pois os caracteres sÃ£o os mesmos rearranjados de outra maneira. Uma funÃ§Ã£o de hash deve ser cuidadosamente definida para tratar este tipo de problema caso ele venha a ser recorrente; caso contrÃ¡rio, teremos excessivas colisÃµes.

#### O mÃ©todo da multiplicaÃ§Ã£o

Esse mÃ©todo de construÃ§Ã£o de funÃ§Ãµes hash funciona da maneira que, primeiro, multiplicamos a chave k por uma constante A. Essa constante deve estar em um intervalo 0 < ğ´ < 1 e extrair a fraÃ§Ã£o de kA. Em seguida, multiplicamos esse valor por m e arredondamos o resultado para baixo. â„(ğ‘˜) = âŒŠğ‘š(ğ‘˜ ğ´ ğ‘€ğ‘‚ğ· 1)âŒ‹ 

Esse mÃ©todo apresenta como desvantagem o fato de ser mais lento para execuÃ§Ã£o em relaÃ§Ã£o ao mÃ©todo da divisÃ£o, pois temos mais cÃ¡lculos envolvidos no processo, porÃ©m tem a vantagem de que o valor de m nÃ£o Ã© crÃ­tico, nÃ£o importando o valor escolhido. 

Em contraponto ao mÃ©todo de divisÃ£o, normalmente adotamos um mÃºltiplo de 2 para seu valor, devido Ã  facilidade de implementaÃ§Ã£o. A constante A, embora possa ser qualquer valor dentro do intervalo 0<A< 1, Ã© melhor com alguns determinados valores. Segundo Knuth (1998), um Ã³timo valor para essa constante Ã© A=(âˆš5âˆ’1)/2â‰…0,618.

#### Hashing universal

Considerando que uma chave k qualquer tem a igual probabilidade de ser inserida em qualquer uma das posiÃ§Ãµes de um vetor, em um pior cenÃ¡rio seria possÃ­vel que um conjunto de chaves a serem inseridas caiam sempre na mesma posiÃ§Ã£o do vetor, caso utilizem a mesma funÃ§Ã£o hash h(k). Portanto a complexidade para a inserÃ§Ã£o nessa hash serÃ¡ ğ‘‚(ğ‘›). Podemos evitar esse tipo de problema escolhendo uma funÃ§Ã£o hashing aleatoriamente dentro de um universo H de funÃ§Ãµes. A esta soluÃ§Ã£o chamamos de hashing universal.

Na hashing universal, no inÃ­cio da execuÃ§Ã£o de um algoritmo de inserÃ§Ã£o, sorteamos aleatoriamente uma funÃ§Ã£o de hash dentro de uma classe de funÃ§Ãµes cuidadosamente desenvolvida para a aplicaÃ§Ã£o desejada. A aleatoriedade evita que qualquer entrada de dado resulte no pior caso. Ã‰ bem verdade que a aleatoriedade poderÃ¡ nunca resultar em um caso perfeito, em que nenhuma colisÃ£o ocorre, mas teremos sempre uma boa situaÃ§Ã£o mÃ©dia.

Existe outro mÃ©todo bastante conhecido de implementaÃ§Ã£o de hash universal que emprega matrizes aleatÃ³rias.

### Tabela Hashing de endereÃ§amento aberto e tentativa linear

A tabela hash pode ser implementada de diferentes formas. A implementaÃ§Ã£o impacta diretamente em como os dados sÃ£o inseridos e no tratamento das colisÃµes de hashs.

Podemos desenvolver uma tabela hashing por meio de uma implementaÃ§Ã£o utilizando endereÃ§amento aberto. Nesse tipo de implementaÃ§Ã£o, a tabela Ã© um vetor de dimensÃ£o m e todas suas chaves sÃ£o armazenadas no prÃ³prio vetor. O endereÃ§amento aberto Ã© bastante empregado quando o nÃºmero de hashs a serem armazenadas Ã© pequeno se comparado com o tamanho do vetor.

Ã‰ possÃ­vel implementÃ¡-la utilizando uma estrutura heterogÃªnea do tipo registro, em que temos como campos um valor para ser usado como palavra-chave, podendo ser um inteiro ou alfanumÃ©rico, por exemplo. E temos tambÃ©m um campo que mantÃ©m o status daquela posiÃ§Ã£o, representando se ele estÃ¡ livre, ocupado por uma chave ou se a chave daquela posiÃ§Ã£o jÃ¡ foi removida. 

ColisÃµes: quando uma palavra-chave deve ser posicionada em um espaÃ§o do vetor em que jÃ¡ estÃ¡ ocupado.

Na tentativa linear, sempre que uma colisÃ£o ocorre, tenta-se posicionar a nova chave no prÃ³ximo espaÃ§o imediatamente livre do vetor. 

Caso o algoritmo de tentativa linear fique buscando uma posiÃ§Ã£o vazia indefinidamente atÃ© chegar ao final do vetor e nÃ£o a encontre, ele retorna ao inÃ­cio e busca atÃ© voltar Ã  posiÃ§Ã£o inicialmente testada. Caso nenhum local livre seja localizado, a palavra-chave nÃ£o pode ser inserida.

Para a tentativa linear, todas as funÃ§Ãµes de manipulaÃ§Ã£o da tabela de hash (inserÃ§Ã£o, remoÃ§Ã£o e busca de um elemento) apresentam risco de colisÃ£o para cada tentativa de manipulaÃ§Ã£o. 

Embora essas funÃ§Ãµes apresentem no melhor caso complexidade constante, nÃ£o podemos garantir que elas terÃ£o sempre esse tempo, uma vez que o risco de colisÃ£o Ã© sempre iminente, independentemente da operaÃ§Ã£o. 

AlÃ©m disso, a tratativa linear funciona com agrupamentos primÃ¡rios de dados, ou seja, podem ocorrer longos trechos de endereÃ§os ocupados em sequÃªncia. Como a tentativa linear testa um elemento por vez, sequencialmente, a complexidade para o pior caso sempre serÃ¡ ğ‘‚(ğ‘›) para todas as funÃ§Ãµes apresentadas (inserÃ§Ã£o, busca e remoÃ§Ã£o).

### Tabela Hashing de endereÃ§amento aberto e tentativa quadrÃ¡tica

Na tentativa quadrÃ¡tica, sempre que uma colisÃ£o ocorre, tenta-se posicionar a nova chave no prÃ³ximo espaÃ§o que estÃ¡ d posiÃ§Ãµes de distÃ¢ncia do primeiro testado, em que 1 â‰¤ ğ‘‘ â‰¤ ğ‘‡ğ´ğ‘€ğ´ğ‘ğ»ğ‘‚_ğ‘‰ğ¸ğ‘‡ğ‘‚ğ‘….

A anÃ¡lise para o pior case da tentativa quadrÃ¡tica nÃ£o difere da tentativa linear. A inserÃ§Ã£o, busca e remoÃ§Ã£o apresenta complexidade BigO ğ‘‚(ğ‘›). Este mÃ©todo acaba por ser mais eficiente em tempo de execuÃ§Ã£o somente para situaÃ§Ãµes de casos mÃ©dios.

### Tabela Hashing com endereÃ§amento em cadeia

Podemos implementar uma tabela hashing empregando conceitos de listas encadeadas. Nesse cenÃ¡rio, temos tambÃ©m um vetor de dimensÃ£o m para representar a tabela, porÃ©m cada posiÃ§Ã£o do vetor armazenarÃ¡ um endereÃ§o para o inÃ­cio de uma lista encadeada, de forma semelhante ao que trabalhamos na construÃ§Ã£o de uma lista de adjacÃªncias em grafos.

A forma como as colisÃµes sÃ£o tratadas por esse tipo de endereÃ§amento Ã© diferente. Nele, nÃ£o Ã© necessÃ¡rio encontrarmos uma nova posiÃ§Ã£o no vetor para alocarmos o elemento colidido. Basta inseri-lo na mesma posiÃ§Ã£o calculada, mas como mais um elemento da lista encadeada simples. A inserÃ§Ã£o Ã© dada sempre antes do Head.

Note que, sempre que necessÃ¡rio buscar uma chave desse vetor, basta recalcular a posiÃ§Ã£o usando a funÃ§Ã£o hashing e, em seguida, varrer a lista encadeada simples daquela posiÃ§Ã£o atÃ© localizar a palavra-chave correspondente.

A complexidade para o endereÃ§amento de cadeia apresenta tempo constante para o pior caso ğ‘‚(1) para a inserÃ§Ã£o na tabela. Esse valor Ã© constante, pois a inserÃ§Ã£o consiste somente em calcular a funÃ§Ã£o hashing e inserir no Head da lista da posiÃ§Ã£o correspondente, sem a necessidade de varredura da lista nem de tratamento de colisÃµes.

Para a remoÃ§Ã£o da lista, o pior cenÃ¡rio seria a necessidade de varrer uma lista encadeada de uma posiÃ§Ã£o buscando um elemento que estÃ¡ na Ãºltima posiÃ§Ã£o dessa lista simplesmente encadeada. Portanto, a complexidade estÃ¡ atrelada ao nÃºmero de palavras-chave (nÃºmeros de elementos) de cada lista encadeada, resultando em ğ‘‚(ğ‘›).